{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n    \n## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \nAuthor: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose.","metadata":{"_uuid":"3f6c2bfe6b2e26c92357e896a1511195d836956e"}},{"cell_type":"markdown","source":"## <center> Assignment 4. Sarcasm detection with logistic regression\n    \nWe'll be using the dataset from the [paper](https://arxiv.org/abs/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https://www.kaggle.com/danofer/sarcasm).\n\nSarcasm detection is easy. \n<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />","metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0"}},{"cell_type":"code","source":"!ls ../input/sarcasm/","metadata":{"_uuid":"23a833b42b3c214b5191dfdc2482f2f901118247","execution":{"iopub.status.busy":"2021-10-16T18:38:17.732325Z","iopub.execute_input":"2021-10-16T18:38:17.732897Z","iopub.status.idle":"2021-10-16T18:38:18.525543Z","shell.execute_reply.started":"2021-10-16T18:38:17.732834Z","shell.execute_reply":"2021-10-16T18:38:18.524742Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom string import punctuation","metadata":{"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4","execution":{"iopub.status.busy":"2021-10-16T19:25:44.375069Z","iopub.execute_input":"2021-10-16T19:25:44.375408Z","iopub.status.idle":"2021-10-16T19:25:44.382688Z","shell.execute_reply.started":"2021-10-16T19:25:44.375349Z","shell.execute_reply":"2021-10-16T19:25:44.381648Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')","metadata":{"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856","execution":{"iopub.status.busy":"2021-10-16T19:14:39.542626Z","iopub.execute_input":"2021-10-16T19:14:39.543096Z","iopub.status.idle":"2021-10-16T19:14:47.708672Z","shell.execute_reply.started":"2021-10-16T19:14:39.543051Z","shell.execute_reply":"2021-10-16T19:14:47.707823Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27","execution":{"iopub.status.busy":"2021-10-16T19:14:47.710062Z","iopub.execute_input":"2021-10-16T19:14:47.710521Z","iopub.status.idle":"2021-10-16T19:14:47.757486Z","shell.execute_reply.started":"2021-10-16T19:14:47.710390Z","shell.execute_reply":"2021-10-16T19:14:47.756332Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"_uuid":"0a7ed9557943806c6813ad59c3d5ebdb403ffd78","execution":{"iopub.status.busy":"2021-10-16T19:14:47.758976Z","iopub.execute_input":"2021-10-16T19:14:47.759221Z","iopub.status.idle":"2021-10-16T19:14:48.558079Z","shell.execute_reply.started":"2021-10-16T19:14:47.759178Z","shell.execute_reply":"2021-10-16T19:14:48.556840Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Some comments are missing, so we drop the corresponding rows.","metadata":{"_uuid":"6472f52fb5ecb8bb2a6e3b292678a2042fcfe34c"}},{"cell_type":"code","source":"train_df.dropna(subset=['comment'], inplace=True)","metadata":{"_uuid":"97b2d85627fcde52a506dbdd55d4d6e4c87d3f08","execution":{"iopub.status.busy":"2021-10-16T19:14:48.559264Z","iopub.execute_input":"2021-10-16T19:14:48.559498Z","iopub.status.idle":"2021-10-16T19:14:48.880496Z","shell.execute_reply.started":"2021-10-16T19:14:48.559453Z","shell.execute_reply":"2021-10-16T19:14:48.879439Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"We notice that the dataset is indeed balanced","metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b"}},{"cell_type":"code","source":"train_df['label'].value_counts()","metadata":{"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11","execution":{"iopub.status.busy":"2021-10-16T19:14:58.233583Z","iopub.execute_input":"2021-10-16T19:14:58.233961Z","iopub.status.idle":"2021-10-16T19:14:58.254684Z","shell.execute_reply.started":"2021-10-16T19:14:58.233899Z","shell.execute_reply":"2021-10-16T19:14:58.253620Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"We split data into training and validation parts.","metadata":{"_uuid":"5b836574e5093c5eb2e9063fefe1c8d198dcba79"}},{"cell_type":"code","source":"train_texts, val_texts, y_train, y_val = train_test_split(train_df[\"comment\"], \n                                                             train_df[\"label\"], \n                                                             random_state=17)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:29:44.966847Z","iopub.execute_input":"2021-10-16T19:29:44.967204Z","iopub.status.idle":"2021-10-16T19:29:45.377578Z","shell.execute_reply.started":"2021-10-16T19:29:44.967146Z","shell.execute_reply":"2021-10-16T19:29:45.376365Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Tasks:\n1. Analyze the dataset, make some plots. This [Kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) might serve as an example\n2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)\n4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n\n## Links:\n  - Machine learning library [Scikit-learn](https://scikit-learn.org/stable/index.html) (a.k.a. sklearn)\n  - Kernels on [logistic regression](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification) and its applications to [text classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), also a [Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection) on feature engineering and feature selection\n  - [Kaggle Kernel](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) \"Approaching (Almost) Any NLP Problem on Kaggle\"\n  - [ELI5](https://github.com/TeamHG-Memex/eli5) to explain model predictions","metadata":{"_uuid":"7f0f47b98e49a185cd5cffe19fcbe28409bf00c0"}},{"cell_type":"markdown","source":"1. Analyze the dataset, make some plots. This Kernel might serve as an example","metadata":{}},{"cell_type":"code","source":"label_count = train_df[\"label\"].value_counts()\nax = label_count.plot.bar(color=['r', 'g'])\nax.set(xlabel='Labels', ylabel='Number of occurences')\nax.xaxis.label.set_size(15)\nax.yaxis.label.set_size(15)\nax.set_title('Counts by values', fontsize=20)\nax.set_xticklabels(ax.get_xticks(), rotation=1, fontsize=15)\nplt.gcf().set(figwidth=14, figheight=8);","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:15:09.092420Z","iopub.execute_input":"2021-10-16T19:15:09.092758Z","iopub.status.idle":"2021-10-16T19:15:09.497840Z","shell.execute_reply.started":"2021-10-16T19:15:09.092707Z","shell.execute_reply":"2021-10-16T19:15:09.497070Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.pie(label_count.values, startangle=90, autopct='%d%%', textprops={\"fontsize\": 15})\nplt.legend(label_count.index, fontsize=15)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:15:10.916391Z","iopub.execute_input":"2021-10-16T19:15:10.916846Z","iopub.status.idle":"2021-10-16T19:15:11.098428Z","shell.execute_reply.started":"2021-10-16T19:15:10.916803Z","shell.execute_reply":"2021-10-16T19:15:11.097521Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def plot_word_cloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24, 16), title=None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS).union({'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'})\n    \n    wordcloud = WordCloud(background_color='black', stopwords=stopwords, max_words=max_words, max_font_size=max_font_size, random_state=42,\n                         width=800, height=400, mask=mask)\n    wordcloud.generate(str(text))\n\n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation='bilinear');\n        plt.title(title, fontdict={'size': title_size, 'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud)\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', 'verticalalignment': 'bottom'})\n    \n    plt.axis('off')\n\nplot_word_cloud(train_df['comment'])\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:15:11.103847Z","iopub.execute_input":"2021-10-16T19:15:11.104365Z","iopub.status.idle":"2021-10-16T19:15:12.367060Z","shell.execute_reply.started":"2021-10-16T19:15:11.104291Z","shell.execute_reply":"2021-10-16T19:15:12.366262Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['label']==0, 'comment'].str.len().apply(np.log1p).hist(alpha=0.5)\ntrain_df.loc[train_df['label']==1, 'comment'].str.len().apply(np.log1p).hist(alpha=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:15:12.368427Z","iopub.execute_input":"2021-10-16T19:15:12.368889Z","iopub.status.idle":"2021-10-16T19:15:13.454702Z","shell.execute_reply.started":"2021-10-16T19:15:12.368836Z","shell.execute_reply":"2021-10-16T19:15:13.453706Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Class label 0 and 1 have identical distributions.","metadata":{}},{"cell_type":"code","source":"def generate_ngrams(text, n_gram=1):\n    tokens = [token.strip() for token in text.strip().lower().split() if token not in STOPWORDS.union(set(list(punctuation)))]\n    ngrams = zip(*[tokens[i:] for i in range(n_gram)])\n    return [\" \".join(ngram) for ngram in ngrams]\n\ndef freq_dict_gen(series, n_gram=1):\n    freq_dict={}\n    for text in series:\n        ngrams = generate_ngrams(text, n_gram=n_gram)\n        for words in ngrams:\n            freq_dict[words] = freq_dict.get(words, 0) + 1 \n    return dict(sorted(freq_dict.items(), key=lambda x: x[1] * -1))\n\ndef horizontal_bar(freq_dict, figsize=(10, 20), take=50, ax=None, title=None, color=None):\n\n    if not ax:\n        plt.figure(figsize=figsize)\n        ax = plt.gca()\n        \n    y = list(freq_dict.keys())[:take][::-1]\n    width = list(freq_dict.values())[:take][::-1]\n    ax.barh(y=y, width=width, color=color)\n    y_min, y_max = ax.get_ylim()\n    ax.set_ylim(y_min + 2 * (take / 50), y_max - 2 * (take / 50))\n    ax.set_title(title, fontsize=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:15:13.456242Z","iopub.execute_input":"2021-10-16T19:15:13.456793Z","iopub.status.idle":"2021-10-16T19:15:13.470217Z","shell.execute_reply.started":"2021-10-16T19:15:13.456733Z","shell.execute_reply":"2021-10-16T19:15:13.469311Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"comments_0 = train_df.loc[train_df['label']==0, 'comment']\ncomments_1 = train_df.loc[train_df['label']==1, 'comment']","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:15:13.471737Z","iopub.execute_input":"2021-10-16T19:15:13.472284Z","iopub.status.idle":"2021-10-16T19:15:13.573391Z","shell.execute_reply.started":"2021-10-16T19:15:13.472208Z","shell.execute_reply":"2021-10-16T19:15:13.572587Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#ngram=1\nfreq_dict_0 = freq_dict_gen(comments_0, n_gram=1)\nfreq_dict_1 = freq_dict_gen(comments_1, n_gram=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:15:13.574384Z","iopub.execute_input":"2021-10-16T19:15:13.574749Z","iopub.status.idle":"2021-10-16T19:16:04.348952Z","shell.execute_reply.started":"2021-10-16T19:15:13.574711Z","shell.execute_reply":"2021-10-16T19:16:04.347880Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nhorizontal_bar(freq_dict_0, take=50, title='Label 0 for n_gram = 1', color='blue', ax=plt.subplot(121))\nhorizontal_bar(freq_dict_1, take=50, title='Label 1 for n_gram = 1', color='orange', ax=plt.subplot(122))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:16:04.350263Z","iopub.execute_input":"2021-10-16T19:16:04.350536Z","iopub.status.idle":"2021-10-16T19:16:06.657959Z","shell.execute_reply.started":"2021-10-16T19:16:04.350481Z","shell.execute_reply":"2021-10-16T19:16:06.656681Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#ngram=1\nfreq_dict_0 = freq_dict_gen(comments_0, n_gram=2)\nfreq_dict_1 = freq_dict_gen(comments_1, n_gram=2)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:16:06.659639Z","iopub.execute_input":"2021-10-16T19:16:06.659995Z","iopub.status.idle":"2021-10-16T19:17:01.957028Z","shell.execute_reply.started":"2021-10-16T19:16:06.659925Z","shell.execute_reply":"2021-10-16T19:17:01.955861Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nhorizontal_bar(freq_dict_0, take=50, title='Label 0 for n_gram = 2', color='blue', ax=plt.subplot(121))\nhorizontal_bar(freq_dict_1, take=50, title='Label 1 for n_gram = 2', color='orange', ax=plt.subplot(122))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:17:01.958502Z","iopub.execute_input":"2021-10-16T19:17:01.958752Z","iopub.status.idle":"2021-10-16T19:17:04.475826Z","shell.execute_reply.started":"2021-10-16T19:17:01.958706Z","shell.execute_reply":"2021-10-16T19:17:04.474640Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#ngram=1\nfreq_dict_0 = freq_dict_gen(comments_0, n_gram=3)\nfreq_dict_1 = freq_dict_gen(comments_1, n_gram=3)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:17:04.477211Z","iopub.execute_input":"2021-10-16T19:17:04.477465Z","iopub.status.idle":"2021-10-16T19:17:58.034126Z","shell.execute_reply.started":"2021-10-16T19:17:04.477420Z","shell.execute_reply":"2021-10-16T19:17:58.033397Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nhorizontal_bar(freq_dict_0, take=50, title='Label 0 for n_gram = 3', color='blue', ax=plt.subplot(121))\nhorizontal_bar(freq_dict_1, take=50, title='Label 1 for n_gram = 3', color='orange', ax=plt.subplot(122))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:17:58.035310Z","iopub.execute_input":"2021-10-16T19:17:58.035829Z","iopub.status.idle":"2021-10-16T19:18:00.638844Z","shell.execute_reply.started":"2021-10-16T19:17:58.035770Z","shell.execute_reply":"2021-10-16T19:18:00.638117Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:18:00.640297Z","iopub.execute_input":"2021-10-16T19:18:00.640555Z","iopub.status.idle":"2021-10-16T19:18:00.673054Z","shell.execute_reply.started":"2021-10-16T19:18:00.640505Z","shell.execute_reply":"2021-10-16T19:18:00.671520Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:18:00.674470Z","iopub.execute_input":"2021-10-16T19:18:00.674761Z","iopub.status.idle":"2021-10-16T19:18:00.687151Z","shell.execute_reply.started":"2021-10-16T19:18:00.674706Z","shell.execute_reply":"2021-10-16T19:18:00.686344Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#which subreddits contain the most label 1 comments\nsubreddit = train_df.groupby([\"subreddit\"])['label'].agg([np.size, np.mean, np.sum])\nsubreddit.sort_values(by='sum', ascending=False).head(20)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:18:00.688670Z","iopub.execute_input":"2021-10-16T19:18:00.689111Z","iopub.status.idle":"2021-10-16T19:18:01.079776Z","shell.execute_reply.started":"2021-10-16T19:18:00.688957Z","shell.execute_reply":"2021-10-16T19:18:01.078538Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#which author tends to make sarcastic comments than others\nauthor = train_df.groupby(by='author')['label'].agg([np.size, np.mean, np.sum])\nauthor.sort_values(by='sum', ascending=False, inplace=True)\nauthor.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:18:01.081372Z","iopub.execute_input":"2021-10-16T19:18:01.081726Z","iopub.status.idle":"2021-10-16T19:18:04.121220Z","shell.execute_reply.started":"2021-10-16T19:18:01.081648Z","shell.execute_reply":"2021-10-16T19:18:04.120202Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (label) based on the text of a comment on Reddit (comment).","metadata":{}},{"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features=50000,  ngram_range=(1, 2), min_df=2)\n# X_train = tfidf.fit_transform(train_texts)\n# X_val = tfidf.fit_transform(val_texts)\npipeline = Pipeline([('tfidf', tfidf), (\"logreg\", LogisticRegression())])\npipeline.fit(train_texts, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:26:25.726766Z","iopub.execute_input":"2021-10-16T20:26:25.727102Z","iopub.status.idle":"2021-10-16T20:27:36.022077Z","shell.execute_reply.started":"2021-10-16T20:26:25.727048Z","shell.execute_reply":"2021-10-16T20:27:36.021177Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"#train accuracy\npipeline.score(train_texts, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:27:36.023613Z","iopub.execute_input":"2021-10-16T20:27:36.023908Z","iopub.status.idle":"2021-10-16T20:28:04.846881Z","shell.execute_reply.started":"2021-10-16T20:27:36.023852Z","shell.execute_reply":"2021-10-16T20:28:04.845658Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"#val accuracy\naccuracy_score(y_val, pipeline.predict(val_texts))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:28:04.848567Z","iopub.execute_input":"2021-10-16T20:28:04.848931Z","iopub.status.idle":"2021-10-16T20:28:14.330019Z","shell.execute_reply.started":"2021-10-16T20:28:04.848865Z","shell.execute_reply":"2021-10-16T20:28:14.329225Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"dir(pipeline)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:29:04.576234Z","iopub.execute_input":"2021-10-16T20:29:04.576562Z","iopub.status.idle":"2021-10-16T20:29:04.584589Z","shell.execute_reply.started":"2021-10-16T20:29:04.576510Z","shell.execute_reply":"2021-10-16T20:29:04.583508Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"code","source":"pipeline.classes_","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:30:17.631893Z","iopub.execute_input":"2021-10-16T20:30:17.632266Z","iopub.status.idle":"2021-10-16T20:30:17.638447Z","shell.execute_reply.started":"2021-10-16T20:30:17.632193Z","shell.execute_reply":"2021-10-16T20:30:17.637572Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"import eli5\neli5.show_weights(estimator=pipeline.named_steps['logreg'],\n                  vec=pipeline.named_steps['tfidf'])","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:28:42.263151Z","iopub.execute_input":"2021-10-16T20:28:42.263677Z","iopub.status.idle":"2021-10-16T20:28:42.423140Z","shell.execute_reply.started":"2021-10-16T20:28:42.263632Z","shell.execute_reply":"2021-10-16T20:28:42.422017Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"markdown","source":"3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)","metadata":{}},{"cell_type":"code","source":"pred_y_val = pipeline.predict(val_texts)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T19:47:13.038097Z","iopub.execute_input":"2021-10-16T19:47:13.038663Z","iopub.status.idle":"2021-10-16T19:47:22.521187Z","shell.execute_reply.started":"2021-10-16T19:47:13.038612Z","shell.execute_reply":"2021-10-16T19:47:22.520384Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"normalize = True\ncm = confusion_matrix(y_val, pred_y_val).T\ndisplay(pd.DataFrame(cm, index=pd.Series(['0', '1'], \n                                         name='Predicted'), \n                     columns=pd.Series(['0', '1'], \n                                       name='Actual')))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:03:25.518215Z","iopub.execute_input":"2021-10-16T20:03:25.518702Z","iopub.status.idle":"2021-10-16T20:03:25.935198Z","shell.execute_reply.started":"2021-10-16T20:03:25.518658Z","shell.execute_reply":"2021-10-16T20:03:25.934503Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"import matplotlib \ndef plot_confusion_matrix(cm, normalize=False, cmap='Blues', figsize=(12, 8), title='Confusion Matrix'):\n    if normalize == True:\n        cm = cm / cm.sum(axis=1)\n    sns.heatmap(cm, \n                annot=True, \n                fmt=\".2f\" if normalize == True else \"d\",\n               xticklabels=[\"0\", \"1\"],\n               yticklabels=[\"0\", \"1\"],\n               cmap=cmap,\n               annot_kws={'fontsize': int(figsize[0] / 12 * 15)})\n    plt.gcf().set(figwidth=figsize[0], figheight=figsize[1])\n    plt.xticks(fontsize=15)\n    plt.yticks(fontsize=15, rotation=0)\n    plt.xlabel('Actual', fontsize=15)\n    plt.ylabel('Predicted', fontsize=15, rotation=0, labelpad=50)\n    plt.title(title, fontsize=figsize[0] / 12 * 20, pad=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:05:21.958054Z","iopub.execute_input":"2021-10-16T20:05:21.958709Z","iopub.status.idle":"2021-10-16T20:05:21.967350Z","shell.execute_reply.started":"2021-10-16T20:05:21.958656Z","shell.execute_reply":"2021-10-16T20:05:21.966517Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(cm, figsize=(12, 8))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:05:22.073432Z","iopub.execute_input":"2021-10-16T20:05:22.074036Z","iopub.status.idle":"2021-10-16T20:05:22.480876Z","shell.execute_reply.started":"2021-10-16T20:05:22.073984Z","shell.execute_reply":"2021-10-16T20:05:22.479807Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n","metadata":{}},{"cell_type":"code","source":"subreddit = train_df[\"subreddit\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:11:18.257103Z","iopub.execute_input":"2021-10-16T20:11:18.257458Z","iopub.status.idle":"2021-10-16T20:11:18.262170Z","shell.execute_reply.started":"2021-10-16T20:11:18.257395Z","shell.execute_reply":"2021-10-16T20:11:18.261295Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"train_subreddit, val_subreddit = train_test_split(subreddit, random_state=17) ","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:22:16.280752Z","iopub.execute_input":"2021-10-16T20:22:16.281281Z","iopub.status.idle":"2021-10-16T20:22:16.482616Z","shell.execute_reply.started":"2021-10-16T20:22:16.280993Z","shell.execute_reply":"2021-10-16T20:22:16.481924Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"X_sub_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:22:32.650026Z","iopub.execute_input":"2021-10-16T20:22:32.650380Z","iopub.status.idle":"2021-10-16T20:22:32.656268Z","shell.execute_reply.started":"2021-10-16T20:22:32.650323Z","shell.execute_reply":"2021-10-16T20:22:32.655551Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"X_com_train = tfidf.fit_transform(train_texts)\nX_com_val = tfidf.transform(val_texts)\nX_sub_train = tfidf.fit_transform(train_subreddit)\nX_sub_val = tfidf.transform(val_subreddit)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:22:59.199131Z","iopub.execute_input":"2021-10-16T20:22:59.199519Z","iopub.status.idle":"2021-10-16T20:24:02.443838Z","shell.execute_reply.started":"2021-10-16T20:22:59.199458Z","shell.execute_reply":"2021-10-16T20:24:02.442993Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"from scipy.sparse import hstack","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:16:39.665285Z","iopub.execute_input":"2021-10-16T20:16:39.665643Z","iopub.status.idle":"2021-10-16T20:16:39.670280Z","shell.execute_reply.started":"2021-10-16T20:16:39.665583Z","shell.execute_reply":"2021-10-16T20:16:39.668999Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(hstack([X_com_train, X_sub_train]), y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:24:02.444924Z","iopub.execute_input":"2021-10-16T20:24:02.445336Z","iopub.status.idle":"2021-10-16T20:24:58.992115Z","shell.execute_reply.started":"2021-10-16T20:24:02.445274Z","shell.execute_reply":"2021-10-16T20:24:58.991258Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"logreg.score(hstack([X_com_train, X_sub_train]), y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:24:58.993472Z","iopub.execute_input":"2021-10-16T20:24:58.993976Z","iopub.status.idle":"2021-10-16T20:25:00.099143Z","shell.execute_reply.started":"2021-10-16T20:24:58.993918Z","shell.execute_reply":"2021-10-16T20:25:00.098290Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"X_sub_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:25:00.101365Z","iopub.execute_input":"2021-10-16T20:25:00.101880Z","iopub.status.idle":"2021-10-16T20:25:00.109231Z","shell.execute_reply.started":"2021-10-16T20:25:00.101820Z","shell.execute_reply":"2021-10-16T20:25:00.108081Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_val, logreg.predict(hstack([X_com_val, X_sub_val])))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:25:49.019778Z","iopub.execute_input":"2021-10-16T20:25:49.020085Z","iopub.status.idle":"2021-10-16T20:25:49.305717Z","shell.execute_reply.started":"2021-10-16T20:25:49.020036Z","shell.execute_reply":"2021-10-16T20:25:49.304728Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_val, hstack([X_com_val, X_sub_val]))\nplot_confusion_matrix(cm)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:25:00.636655Z","iopub.status.idle":"2021-10-16T20:25:00.637003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}